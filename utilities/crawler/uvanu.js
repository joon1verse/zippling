// ğŸ“„ uvanu.js â€” Daum Cafe - UvanU í¬ë¡¤ëŸ¬ (ì„œë²„ë¦¬ìŠ¤ Cron Job ë²„ì „)

import axios from 'axios';
import { load } from 'cheerio';
import { getSourceInfo } from '../sourceMap.js';
import { uploadToSupabase } from '../supabaseUploader.js';

// (uvanu-1) ëŒ€ìƒ URL
const TARGET_URL = 'https://m.cafe.daum.net/ourvancouver/4Nd0';

// (uvanu-2) íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± í•¨ìˆ˜
const getTimestamp = () => {
  const now = new Date();
  const pad = (n) => n.toString().padStart(2, '0');
  return `${now.getFullYear()}${pad(now.getMonth() + 1)}${pad(now.getDate())}-${pad(now.getHours())}${pad(now.getMinutes())}`;
};

// (uvanu-3) í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜
async function crawlUvanU() {
  const timestamp = getTimestamp();
  const outputFileName = `uvanu_${timestamp}.json`;

  try {
    const { data: html } = await axios.get(TARGET_URL, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
      },
    });

    const $ = load(html);
    const rawPosts = [];

    $('li').each((_, el) => {
      if (rawPosts.length >= 20) return false;

      const li = $(el);
      const liText = li.text();
      if (liText.includes('ê³µì§€') || liText.includes('í•„ë…')) return;

      const title = li.find('.txt_detail').text().trim();
      const href = li.find('a').attr('href');
      const link = href ? 'https://m.cafe.daum.net' + href : null;

      if (title && link) {
        const lowerTitle = title.toLowerCase();
        const maleKeywords = ['ë‚¨ì„±', 'ë‚¨ì', 'ç”·æ€§', 'man', 'male', 'boy'];
        const femaleKeywords = ['ì—¬ì„±', 'ì—¬ì', 'å¥³æ€§', 'woman', 'female', 'girl'];

        const hasMale = maleKeywords.some(keyword => new RegExp(`\\b${keyword}\\b`, 'i').test(lowerTitle));
        const hasFemale = femaleKeywords.some(keyword => new RegExp(`\\b${keyword}\\b`, 'i').test(lowerTitle));

        const tags = [];
        if (hasMale && !hasFemale) tags.push('male');
        else if (hasFemale && !hasMale) tags.push('female');
        else tags.push('no-gender');

        tags.push('korea');

        const { source } = getSourceInfo(link);
        rawPosts.push({
          title,
          link,
          tag: tags,
          source,
          crawledAt: new Date().toISOString(),
        });
      }
    });

    const jsonData = JSON.stringify(rawPosts, null, 2);

    await uploadToSupabase(
      'zippling-data',
      `rawdata/vancouver/${outputFileName}`,
      jsonData
    );

    console.log(`âœ… í¬ë¡¤ë§ ë°ì´í„° ${rawPosts.length}ê°œ Supabase ì§ì ‘ ì—…ë¡œë“œ ì™„ë£Œ`);
  } catch (err) {
    console.error('âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', err.message);
  }
}

// (uvanu-4) cron job ì‹¤í–‰ ì‹œ ì§ì ‘ í˜¸ì¶œ
crawlUvanU();
