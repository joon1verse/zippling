// ðŸ“„ index.js â€” í¬ë¡¤ë§ ë°ì´í„° ë³‘í•© ë° ì €ìž¥ ì‹¤í–‰ íŒŒì¼
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';
import { getMergedDataByTag, saveMergedData } from './merger.js';

// â›“ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬ (í˜„ìž¬ íŒŒì¼ ê¸°ì¤€)
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// ðŸ“ í¬ë¡¤ë§ ì›ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬
const dataDir = path.join(__dirname, 'crawler', 'rawdata');

// âœ… ì›ë³¸ íŒŒì¼ ì½ê¸° í•¨ìˆ˜ (uvanu, craigslist ë“±)
const loadRawFiles = (prefix) => {
  return fs.readdirSync(dataDir)
    .filter(file => file.startsWith(`${prefix}_`) && file.endsWith('.json'))
    .map(file => {
      const filePath = path.join(dataDir, file);
      const jsonData = JSON.parse(fs.readFileSync(filePath, 'utf-8'));
      return {
        source: prefix,
        data: jsonData,
      };
    });
};

// ðŸ§© ëª¨ë“  í¬ë¡¤ë§ ì†ŒìŠ¤ ë¡œë”©
const crawledDataList = [
  ...loadRawFiles('uvanu'),
  ...loadRawFiles('craigslist'),
];

// ðŸ“¦ íƒœê·¸ë³„ ë³‘í•© ë° ì €ìž¥
['vancouver'].forEach(tag => {
  const tagData = getMergedDataByTag(tag, crawledDataList);
  saveMergedData(tag, tagData);
});
